{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e530359-10ec-43d4-a6cc-7ff3dc378033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dbnl\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import UTC, datetime, timedelta\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Make sure your version matches the docs at https://docs.dbnl.com/\n",
    "print(\"dbnl version:\", dbnl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0306de-20c2-4c64-af5e-041ad06a777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to DBNL (using default Sandbox url)\n",
    "dbnl.login(\n",
    "    api_url=\"http://localhost:8080/api\",\n",
    "    api_token=\"<DBNL_API_KEY>\", # found at http://localhost:8080/tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba715c9-eafa-4a20-8da9-efe55bc3aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new project\n",
    "project = dbnl.get_or_create_project(\n",
    "    name=\"ADK Calc Traces SDK via OTEL Two Week Simulation\",\n",
    "    schedule=\"daily\",  # How often DBNL analyzes new data\n",
    "    default_llm_model_name=\"quickstart_demo\" # From step (2) in quickstart\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faed2b15-4623-46d4-9465-80e4f34c1a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dbnl_otel_converter import dbnl_df_from_otel_file\n",
    "\n",
    "df = dbnl_df_from_otel_file(\"traces.jsonl\")\n",
    "\n",
    "print(f\"Loaded {len(df)} traces.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdde5a1e-e106-4d41-a4bb-819d94802ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for augmentation\n",
    "\n",
    "def break_into_days(df, start_day, num_days, variation=0.10):\n",
    "    \"\"\"\n",
    "    Split dataframe into daily chunks with ±variation in size.\n",
    "    Ensures all rows are used exactly once.\n",
    "    \"\"\"\n",
    "    total_rows = len(df)\n",
    "    base = total_rows / num_days\n",
    "    sizes = []\n",
    "    for _ in range(num_days):\n",
    "        factor = 1 + np.random.uniform(-variation, variation)\n",
    "        sizes.append(int(base * factor))\n",
    "\n",
    "    scale = total_rows / sum(sizes)\n",
    "    sizes = [int(s * scale) for s in sizes]\n",
    "    sizes[-1] = total_rows - sum(sizes[:-1])\n",
    "\n",
    "    day_dfs = []\n",
    "    idx = 0\n",
    "    for day_idx, size in enumerate(sizes):\n",
    "        chunk = df.iloc[idx : idx + size].copy()\n",
    "        idx += size\n",
    "\n",
    "        chunk[\"timestamp\"] = start_day.replace(hour=12) + timedelta(days=day_idx)\n",
    "\n",
    "        for row in chunk.itertuples(index=True):\n",
    "            chunk.at[row.Index, \"timestamp\"] = randomize_timestamps_within_day(row)\n",
    "            \n",
    "        day_dfs.append(chunk.reset_index(drop=True))\n",
    "\n",
    "    return day_dfs\n",
    "\n",
    "def randomize_timestamps_within_day(row):\n",
    "    rand_hour = random.randint(0, 23)\n",
    "    rand_min = random.randint(0, 59)\n",
    "    rand_sec = random.randint(0, 59)\n",
    "    return row.timestamp.replace(\n",
    "                hour=rand_hour,\n",
    "                minute=rand_min,\n",
    "                second=rand_sec,\n",
    "    )\n",
    "\n",
    "# Short messages (customize as you like)\n",
    "complaints = [\n",
    "    \"That’s not right!\",\n",
    "    \"Wrong result again!\",\n",
    "    \"Calculator failed.\",\n",
    "    \"Off by a mile.\",\n",
    "    \"Bad math output!\",\n",
    "    \"Totally incorrect!\",\n",
    "    \"Oops, wrong calc.\",\n",
    "    \"Computation error.\",\n",
    "    \"Answer is wrong.\",\n",
    "    \"Incorrect result.\",\n",
    "    \"Math seems broken.\",\n",
    "    \"Calculation flaw.\",\n",
    "    \"Miscalculated that.\",\n",
    "    \"Wrong total shown.\",\n",
    "    \"Completely off!\",\n",
    "    \"This seems buggy.\",\n",
    "    \"Bad arithmetic!\",\n",
    "    \"The math is wrong.\",\n",
    "    \"Way off the mark.\",\n",
    "    \"Error in result!\",\n",
    "]\n",
    "praises = [\n",
    "    \"Perfect result!\",\n",
    "    \"Nice work!\",\n",
    "    \"Correct again!\",\n",
    "    \"Spot on!\",\n",
    "    \"You nailed it!\",\n",
    "    \"Looks good!\",\n",
    "    \"Math checks out!\",\n",
    "    \"Well done!\",\n",
    "    \"Accurate answer!\",\n",
    "    \"Exactly right!\",\n",
    "    \"All good here!\",\n",
    "    \"Bang on target!\",\n",
    "    \"That’s correct!\",\n",
    "    \"Great calculation!\",\n",
    "    \"Awesome result!\",\n",
    "    \"Nice precision!\",\n",
    "    \"Flawless math!\",\n",
    "    \"Right on point!\",\n",
    "    \"Excellent job!\",\n",
    "    \"Spotless result!\",\n",
    "]\n",
    "\n",
    "COST = {  # per token (Gemini 2.5 Flash pricing)\n",
    "    \"gen_ai.usage.input_tokens\": 0.000000075,\n",
    "    \"gen_ai.usage.output_tokens\": 0.00000030,\n",
    "}\n",
    "\n",
    "def est_cost_from_gen_ai_tokens(spans):\n",
    "    \"\"\"Sum gen_ai.usage.input_tokens + gen_ai.usage.output_tokens across all spans.\"\"\"\n",
    "    if spans is None:\n",
    "        return 0\n",
    "\n",
    "    total = 0\n",
    "    for span in spans:\n",
    "        attrs = span.get(\"attributes\", [])\n",
    "        # attrs is a list of (key, value) tuples\n",
    "        for key, val in attrs:\n",
    "            if key in (\"gen_ai.usage.input_tokens\", \"gen_ai.usage.output_tokens\"):\n",
    "                if isinstance(val, str):\n",
    "                    # strip wrapping quotes if present, then try to parse int\n",
    "                    v = val.strip('\"')\n",
    "                    try:\n",
    "                        total += int(v)*COST[key]\n",
    "                    except ValueError:\n",
    "                        pass  # ignore non-numeric weirdness\n",
    "    return total\n",
    "\n",
    "\n",
    "def get_math_output_from_row(row):\n",
    "    try:\n",
    "        return float(json.loads(json.loads(row[\"output\"]))[\"content\"][\"parts\"][0][\"text\"])\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def compute_feedback(row, p_keep=0.11):\n",
    "    # 89% chance to leave both None\n",
    "    if random.random() > p_keep:\n",
    "        return pd.Series({\"feedback_score\": None, \"feedback_text\": None})\n",
    "\n",
    "    out = get_math_output_from_row(row)\n",
    "    exp = float(row[\"output_expected\"])\n",
    "\n",
    "    if out is not None and exp is not None and out == exp:\n",
    "        score = 5\n",
    "        text = random.choice(praises)\n",
    "    else:\n",
    "        score = 1\n",
    "        text = random.choice(complaints)\n",
    "\n",
    "    # JSON-safe primitives\n",
    "    return pd.Series({\"feedback_score\": int(score), \"feedback_text\": str(text)})\n",
    "\n",
    "\n",
    "def compute_abs_error(row):\n",
    "    out = get_math_output_from_row(row)\n",
    "    if \"output_expected\" in row:\n",
    "        exp = float(row[\"output_expected\"])\n",
    "    else:\n",
    "        exp = compute_expected_answer(row[\"input\"])\n",
    "\n",
    "    if exp is not None and out is not None:\n",
    "        return abs(out - exp)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def compute_expected_answer(input_string: str) -> float | None:\n",
    "    \"\"\"\n",
    "    Parse a math question and compute the expected answer.\n",
    "\n",
    "    Handles various question formats like \"1+2\", \"40-4*6\", etc\n",
    "\n",
    "    Returns:\n",
    "        The computed answer as a float, or None if the question couldn't be parsed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        question = json.loads(json.loads(input_string))[\"new_message\"][\"parts\"][0][\"text\"]\n",
    "        return eval(question)\n",
    "    except Exception:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c707ceb9-20bb-43bb-bcbd-204830948945",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"output_expected\"] = df[\"input\"].apply(compute_expected_answer)\n",
    "df[[\"feedback_score\", \"feedback_text\"]] = df.apply(compute_feedback, axis=1)\n",
    "df[\"absolute_error\"] = df.apply(compute_abs_error, axis=1)\n",
    "raw_spans = df[\"traces_data\"]\n",
    "dbnl_spans = dbnl.convert_otlp_traces_data(data=raw_spans)\n",
    "df[\"total_cost\"] = dbnl_spans.apply(est_cost_from_gen_ai_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da95309-9d02-4b18-b187-9601e3818528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper for sending multiple days of dataframes to DBNL\n",
    "\n",
    "def upload_to_dbnl(day_dfs):\n",
    "    \"\"\"Upload daily dataframes to DBNL.\"\"\"\n",
    "    print(f\"Status: {app_url}/ns/{project.namespace_id}/projects/{project.id}/status\")\n",
    "    for idx, day_df in enumerate(day_dfs):\n",
    "        print(f\"{idx + 1}/{len(day_dfs)} uploading {min(day_df['timestamp']).date()} : {len(day_df)} traces.\")\n",
    "        data_start = min(day_df['timestamp']).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "        data_end = data_start + timedelta(days=1)\n",
    "        try:\n",
    "            dbnl.log(\n",
    "                project_id=project.id,\n",
    "                data_start_time=data_start,\n",
    "                data_end_time=data_end,\n",
    "                data=day_df,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            if \"Data already exists\" in str(e):\n",
    "                print(\"  Data already exists, skipping...\")\n",
    "                continue\n",
    "            raise\n",
    "    print(f\"\\nExplore: {app_url}/ns/{project.namespace_id}/projects/{project.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c669f0-2dda-4031-96af-7beebb03e02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_dfs = break_into_days(df, start_day=datetime.now(tz=UTC) - timedelta(days=2), num_days=2, variation=0.10)\n",
    "upload_to_dbnl(day_dfs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
