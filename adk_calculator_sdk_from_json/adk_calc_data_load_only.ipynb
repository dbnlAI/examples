{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a669a18e-fdb9-47b4-809a-90201d6b1c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dbnl\n",
    "import json\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from datetime import UTC, datetime, timedelta\n",
    "\n",
    "# Make sure your version matches the docs at https://docs.dbnl.com/\n",
    "print(\"dbnl version:\", dbnl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d979dc08-a1bc-47c8-b1cd-06e826e0de15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to DBNL (using default Sandbox url)\n",
    "dbnl.login(\n",
    "    api_url=\"http://localhost:8080/api\",\n",
    "    api_token=\"<DBNL_API_KEY>\", # found at http://localhost:8080/tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad149f2e-f197-4338-b474-b51a7c0f3958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new project\n",
    "project = dbnl.get_or_create_project(\n",
    "    name=\"ADK Calc Traces SDK via JSON\",\n",
    "    schedule=\"daily\",  # How often DBNL analyzes new data\n",
    "    default_llm_model_name=\"quickstart_model\" # From step (2) in https://docs.dbnl.com/get-started/quickstart\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a10f2d-1c41-4543-8a54-04be76a75484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the JSONL file\n",
    "df = pd.read_json('traces.jsonl', lines=True)\n",
    "\n",
    "# Convert timestamp columns to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# For nested timestamps in spans, we also need to convert to datetime\n",
    "def convert_span_times(spans):\n",
    "    for span in spans:\n",
    "        span['start_time'] = pd.to_datetime(span['start_time'])\n",
    "        span['end_time'] = pd.to_datetime(span['end_time'])\n",
    "    return spans\n",
    "\n",
    "df['spans'] = df['spans'].apply(convert_span_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312c2d18-cef5-4c30-9460-636d1783c26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the data is spread across multiple days we need to break it into days for upload\n",
    "df[\"date\"] = df[\"timestamp\"].dt.tz_convert(\"UTC\").dt.date\n",
    "day_dfs = [g.drop(columns=\"date\").reset_index(drop=True)\n",
    "           for _, g in df.groupby(\"date\")]\n",
    "\n",
    "print(\"Uploading data...\")\n",
    "print(f\"See status at: http://localhost:8080/ns/{project.namespace_id}/projects/{project.id}/status\")\n",
    "\n",
    "for idx, day_df in enumerate(day_dfs):\n",
    "    print(f\"{idx + 1} / {len(day_dfs)} publishing log data for {min(day_df['timestamp']).date()}\")\n",
    "    data_start_t = min(day_df['timestamp']).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    data_end_t = data_start_t + timedelta(days=1)\n",
    "    try:\n",
    "        dbnl.log(\n",
    "            project_id=project.id,\n",
    "            data_start_time=data_start_t,\n",
    "            data_end_time=data_end_t,\n",
    "            data=day_df,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        if \"Data already exists\" in str(e):\n",
    "            continue\n",
    "        raise\n",
    "\n",
    "print(\"You can now explore your data in DBNL!\")\n",
    "print(f\"http://localhost:8080/ns/{project.namespace_id}/projects/{project.id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
