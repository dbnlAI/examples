{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e530359-10ec-43d4-a6cc-7ff3dc378033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbnl version: 0.27.1\n"
     ]
    }
   ],
   "source": [
    "import dbnl\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import UTC, datetime, timedelta\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Make sure your version matches the docs at https://docs.dbnl.com/\n",
    "print(\"dbnl version:\", dbnl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d0306de-20c2-4c64-af5e-041ad06a777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_url = \"https://app.dev.dbnl.com/\"\n",
    "api_token = \"eyJhbGciOiJSUzI1NiIsImtpZCI6ImRibmwiLCJ0eXAiOiJKV1QifQ.eyJzY29wZXMiOlsiZGV2Il0sInN1YiI6Imdvb2dsZS1vYXV0aDJ8MTA5NDY1NjQwODIyMTA0MjgxNzE2IiwiaXNzIjoiaHR0cDovL2Rldi5kYm5sLmNvbSIsImF1ZCI6Imh0dHA6Ly9kZXYuZGJubC5jb20iLCJpYXQiOjE3NjM3NjE3NDQsIm9yZ19pZCI6Im9yZ19HQndaeGlMWHNzeFNuOFVZIn0.qJGVSpFMI1vQdw7tDPxhL3S9Wv2D6r3CFWOovKp5lM3Qm7sDlw2BomkGK9d9oTbILZXGlVWYpBNsat1-Whwj3dqWQPUiV0LS1uBl1MJz-UlR4Lp6KNQBQrjT3tc_gOAb0igYHKUS-YEJ0-EiBh_ii7Dz_CWORMuZnRUHfFcdZGAz0COncGiOPcALtKqEaRnjOFMYJgDctmHpkAyy_-qav-q-Va4HbvFBOxkQVsalbEZo8ds3qc5YAjOPcZqMrTWBzfoDd0HmuVG78xjFiE8Fl8J997SUM_Bbr63iNjrqxPojtenmTfhE4TMDzyBqz1Xldyk1Nml0MuBhlW-5LacH4Q\"\n",
    "\n",
    "# Login to DBNL (using default Sandbox url)\n",
    "dbnl.login(\n",
    "    api_url=\"https://api.dev.dbnl.com\",\n",
    "    api_token=api_token, # found at http://localhost:8080/tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fba715c9-eafa-4a20-8da9-efe55bc3aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new project\n",
    "project = dbnl.get_or_create_project(\n",
    "    name=\"ADK Calc Traces SDK via OTEL Two Week Simulation v4\",\n",
    "    schedule=\"daily\",  # How often DBNL analyzes new data\n",
    "    default_llm_model_name=\"nim-gpt-oss-20b\" # From step (2) in quickstart\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "faed2b15-4623-46d4-9465-80e4f34c1a71",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'traces.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdbnl_otel_converter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dbnl_df_from_otel_file\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df = \u001b[43mdbnl_df_from_otel_file\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtraces.jsonl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m traces.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/examples/adk_calculator_sdk_from_otel/dbnl_otel_converter.py:117\u001b[39m, in \u001b[36mdbnl_df_from_otel_file\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdbnl_df_from_otel_file\u001b[39m(path):\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    118\u001b[39m         raw_spans = pd.Series([json.loads(line) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f])\n\u001b[32m    120\u001b[39m     dbnl_spans = dbnl.convert_otlp_traces_data(data=raw_spans)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'traces.jsonl'"
     ]
    }
   ],
   "source": [
    "from dbnl_otel_converter import dbnl_df_from_otel_file\n",
    "\n",
    "df = dbnl_df_from_otel_file(\"traces.jsonl\")\n",
    "\n",
    "print(f\"Loaded {len(df)} traces.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bdde5a1e-e106-4d41-a4bb-819d94802ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for augmentation\n",
    "\n",
    "def break_into_days(df, start_day, num_days, variation=0.10):\n",
    "    \"\"\"\n",
    "    Split dataframe into daily chunks with ±variation in size.\n",
    "    Ensures all rows are used exactly once.\n",
    "    \"\"\"\n",
    "    total_rows = len(df)\n",
    "    base = total_rows / num_days\n",
    "    sizes = []\n",
    "    for _ in range(num_days):\n",
    "        factor = 1 + np.random.uniform(-variation, variation)\n",
    "        sizes.append(int(base * factor))\n",
    "\n",
    "    scale = total_rows / sum(sizes)\n",
    "    sizes = [int(s * scale) for s in sizes]\n",
    "    sizes[-1] = total_rows - sum(sizes[:-1])\n",
    "\n",
    "    day_dfs = []\n",
    "    idx = 0\n",
    "    for day_idx, size in enumerate(sizes):\n",
    "        chunk = df.iloc[idx : idx + size].copy()\n",
    "        idx += size\n",
    "\n",
    "        chunk[\"timestamp\"] = start_day.replace(hour=12) + timedelta(days=day_idx)\n",
    "\n",
    "        for row in chunk.itertuples(index=True):\n",
    "            chunk.at[row.Index, \"timestamp\"] = randomize_timestamps_within_day(row)\n",
    "            \n",
    "        day_dfs.append(chunk.reset_index(drop=True))\n",
    "\n",
    "    return day_dfs\n",
    "\n",
    "def randomize_timestamps_within_day(row):\n",
    "    rand_hour = random.randint(0, 23)\n",
    "    rand_min = random.randint(0, 59)\n",
    "    rand_sec = random.randint(0, 59)\n",
    "    return row.timestamp.replace(\n",
    "                hour=rand_hour,\n",
    "                minute=rand_min,\n",
    "                second=rand_sec,\n",
    "    )\n",
    "\n",
    "# Short messages (customize as you like)\n",
    "complaints = [\n",
    "    \"That’s not right!\",\n",
    "    \"Wrong result again!\",\n",
    "    \"Calculator failed.\",\n",
    "    \"Off by a mile.\",\n",
    "    \"Bad math output!\",\n",
    "    \"Totally incorrect!\",\n",
    "    \"Oops, wrong calc.\",\n",
    "    \"Computation error.\",\n",
    "    \"Answer is wrong.\",\n",
    "    \"Incorrect result.\",\n",
    "    \"Math seems broken.\",\n",
    "    \"Calculation flaw.\",\n",
    "    \"Miscalculated that.\",\n",
    "    \"Wrong total shown.\",\n",
    "    \"Completely off!\",\n",
    "    \"This seems buggy.\",\n",
    "    \"Bad arithmetic!\",\n",
    "    \"The math is wrong.\",\n",
    "    \"Way off the mark.\",\n",
    "    \"Error in result!\",\n",
    "]\n",
    "praises = [\n",
    "    \"Perfect result!\",\n",
    "    \"Nice work!\",\n",
    "    \"Correct again!\",\n",
    "    \"Spot on!\",\n",
    "    \"You nailed it!\",\n",
    "    \"Looks good!\",\n",
    "    \"Math checks out!\",\n",
    "    \"Well done!\",\n",
    "    \"Accurate answer!\",\n",
    "    \"Exactly right!\",\n",
    "    \"All good here!\",\n",
    "    \"Bang on target!\",\n",
    "    \"That’s correct!\",\n",
    "    \"Great calculation!\",\n",
    "    \"Awesome result!\",\n",
    "    \"Nice precision!\",\n",
    "    \"Flawless math!\",\n",
    "    \"Right on point!\",\n",
    "    \"Excellent job!\",\n",
    "    \"Spotless result!\",\n",
    "]\n",
    "\n",
    "COST = {  # per token (Gemini 2.5 Flash pricing)\n",
    "    \"gen_ai.usage.input_tokens\": 0.000000075,\n",
    "    \"gen_ai.usage.output_tokens\": 0.00000030,\n",
    "}\n",
    "\n",
    "def est_cost_from_gen_ai_tokens(spans):\n",
    "    \"\"\"Sum gen_ai.usage.input_tokens + gen_ai.usage.output_tokens across all spans.\"\"\"\n",
    "    if spans is None:\n",
    "        return 0\n",
    "\n",
    "    total = 0\n",
    "    for span in spans:\n",
    "        attrs = span.get(\"attributes\", [])\n",
    "        # attrs is a list of (key, value) tuples\n",
    "        for key, val in attrs:\n",
    "            if key in (\"gen_ai.usage.input_tokens\", \"gen_ai.usage.output_tokens\"):\n",
    "                if isinstance(val, str):\n",
    "                    # strip wrapping quotes if present, then try to parse int\n",
    "                    v = val.strip('\"')\n",
    "                    try:\n",
    "                        total += int(v)*COST[key]\n",
    "                    except ValueError:\n",
    "                        pass  # ignore non-numeric weirdness\n",
    "    return total\n",
    "\n",
    "\n",
    "def get_math_output_from_row(row):\n",
    "    try:\n",
    "        return float(json.loads(json.loads(row[\"output\"]))[\"content\"][\"parts\"][0][\"text\"])\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def compute_feedback(row, p_keep=0.11):\n",
    "    # 89% chance to leave both None\n",
    "    if random.random() > p_keep:\n",
    "        return pd.Series({\"feedback_score\": None, \"feedback_text\": None})\n",
    "\n",
    "    out = get_math_output_from_row(row)\n",
    "    exp = float(row[\"output_expected\"])\n",
    "\n",
    "    if out is not None and exp is not None and out == exp:\n",
    "        score = 5\n",
    "        text = random.choice(praises)\n",
    "    else:\n",
    "        score = 1\n",
    "        text = random.choice(complaints)\n",
    "\n",
    "    # JSON-safe primitives\n",
    "    return pd.Series({\"feedback_score\": int(score), \"feedback_text\": str(text)})\n",
    "\n",
    "\n",
    "def compute_abs_error(row):\n",
    "    out = get_math_output_from_row(row)\n",
    "    if \"output_expected\" in row:\n",
    "        exp = float(row[\"output_expected\"])\n",
    "    else:\n",
    "        exp = compute_expected_answer(row[\"input\"])\n",
    "\n",
    "    if exp is not None and out is not None:\n",
    "        return abs(out - exp)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def compute_expected_answer(input_string: str) -> float | None:\n",
    "    \"\"\"\n",
    "    Parse a math question and compute the expected answer.\n",
    "\n",
    "    Handles various question formats like \"1+2\", \"40-4*6\", etc\n",
    "\n",
    "    Returns:\n",
    "        The computed answer as a float, or None if the question couldn't be parsed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        question = json.loads(json.loads(input_string))[\"new_message\"][\"parts\"][0][\"text\"]\n",
    "        return eval(question)\n",
    "    except Exception:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c707ceb9-20bb-43bb-bcbd-204830948945",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"output_expected\"] = df[\"input\"].apply(compute_expected_answer)\n",
    "df[[\"feedback_score\", \"feedback_text\"]] = df.apply(compute_feedback, axis=1)\n",
    "df[\"absolute_error\"] = df.apply(compute_abs_error, axis=1)\n",
    "raw_spans = df[\"traces_data\"]\n",
    "dbnl_spans = dbnl.convert_otlp_traces_data(data=raw_spans)\n",
    "df[\"total_cost\"] = dbnl_spans.apply(est_cost_from_gen_ai_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3abc4639-607b-4ad4-8c35-e4764c67ab95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trace_id                            088884c78afa668e6f101f1c1a886566\n",
       "input              \"{\\\"user_id\\\": \\\"test-user\\\", \\\"session_id\\\": ...\n",
       "output             \"{\\\"model_version\\\":\\\"gemini-2.5-flash\\\",\\\"con...\n",
       "timestamp                           2025-11-26 22:44:02.636721+00:00\n",
       "traces_data        {'resourceSpans': [{'resource': {'attributes':...\n",
       "output_expected                                               9312.0\n",
       "feedback_score                                                   5.0\n",
       "feedback_text                                        Nice precision!\n",
       "absolute_error                                                   0.0\n",
       "total_cost                                                  0.000078\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7da95309-9d02-4b18-b187-9601e3818528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper for sending multiple days of dataframes to DBNL\n",
    "\n",
    "def upload_to_dbnl(day_dfs):\n",
    "    \"\"\"Upload daily dataframes to DBNL.\"\"\"\n",
    "    print(f\"Status: {app_url}/ns/{project.namespace_id}/projects/{project.id}/status\")\n",
    "    for idx, day_df in enumerate(day_dfs):\n",
    "        print(f\"{idx + 1}/{len(day_dfs)} uploading {min(day_df['timestamp']).date()} : {len(day_df)} traces.\")\n",
    "        data_start = min(day_df['timestamp']).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "        data_end = data_start + timedelta(days=1)\n",
    "        try:\n",
    "            dbnl.log(\n",
    "                project_id=project.id,\n",
    "                data_start_time=data_start,\n",
    "                data_end_time=data_end,\n",
    "                data=day_df,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            if \"Data already exists\" in str(e):\n",
    "                print(\"  Data already exists, skipping...\")\n",
    "                continue\n",
    "            raise\n",
    "    print(f\"\\nExplore: {app_url}/ns/{project.namespace_id}/projects/{project.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34c669f0-2dda-4031-96af-7beebb03e02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_dfs = break_into_days(df, start_day=datetime.now(tz=UTC) - timedelta(days=2), num_days=2, variation=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c0f83927-70a3-4f9f-8040-d3b228ab0cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: https://app.dev.dbnl.com//ns/ns_6EQyidK8jAwDXNth0Ey7DS/projects/proj_gafwBOisrx4ZRMUbUMYUR/status\n",
      "1/2 uploading 2025-11-24 : 9 traces.\n",
      "2/2 uploading 2025-11-25 : 11 traces.\n",
      "\n",
      "Explore: https://app.dev.dbnl.com//ns/ns_6EQyidK8jAwDXNth0Ey7DS/projects/proj_gafwBOisrx4ZRMUbUMYUR\n"
     ]
    }
   ],
   "source": [
    "upload_to_dbnl(day_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119eaed2-3eb6-4376-8972-b6ca48c9c446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
